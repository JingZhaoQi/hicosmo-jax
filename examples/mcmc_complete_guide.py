#!/usr/bin/env python3
"""
HiCosmo MCMC å®Œæ•´ä½¿ç”¨æŒ‡å—

æœ¬ç¤ºä¾‹è¯¦ç»†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ HiCosmo MCMC è¿›è¡Œè´å¶æ–¯æ¨æ–­ï¼Œ
åŒ…æ‹¬æ‰€æœ‰ä¸»è¦åŠŸèƒ½å’Œæ¥å£çš„ä½¿ç”¨æ–¹æ³•ã€‚
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import numpy as np
import matplotlib.pyplot as plt

# ç¬¬ä¸€æ­¥ï¼šä¼˜é›…çš„å¤šæ ¸åˆå§‹åŒ–
print("ğŸš€ HiCosmo MCMC å®Œæ•´ä½¿ç”¨æŒ‡å—")
print("="*60)

print("\nğŸ“ æ­¥éª¤1: ä¼˜é›…çš„å¤šæ ¸åˆå§‹åŒ–")
print("-"*50)
from hicosmo.samplers import Config
Config.init(cpu_cores=4, verbose=True)  # ä¸€è¡Œä»£ç å®Œæˆå¤šæ ¸é…ç½®ï¼

# ç¬¬äºŒæ­¥ï¼šå‡†å¤‡æ•°æ®
print("\nğŸ“ æ­¥éª¤2: å‡†å¤‡æµ‹è¯•æ•°æ®")
print("-"*50)
print("ç”Ÿæˆçº¿æ€§æ¨¡å‹æ•°æ®ï¼šy = a*x + b + noise")

np.random.seed(42)
N_data = 100
x = np.linspace(0, 10, N_data)
true_a, true_b = 2.5, 1.8
y_err = 0.3
y_true = true_a * x + true_b
y_obs = y_true + np.random.normal(0, y_err, N_data)

print(f"æ•°æ®ç‚¹æ•°: {N_data}")
print(f"çœŸå®å‚æ•°: a = {true_a}, b = {true_b}")
print(f"è§‚æµ‹å™ªå£°: Ïƒ = {y_err}")

# ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰ä¼¼ç„¶å‡½æ•°
print("\nğŸ“ æ­¥éª¤3: å®šä¹‰ä¼¼ç„¶å‡½æ•°")
print("-"*50)
def linear_likelihood(a, b):
    """
    çº¿æ€§æ¨¡å‹çš„ä¼¼ç„¶å‡½æ•°
    
    Parameters:
    -----------
    a, b : float
        æ¨¡å‹å‚æ•°
        
    Returns:
    --------
    float
        å¯¹æ•°ä¼¼ç„¶å€¼
    """
    y_pred = a * x + b
    chi2 = np.sum((y_obs - y_pred)**2 / y_err**2)
    return -0.5 * chi2

print("å®šä¹‰ä¼¼ç„¶å‡½æ•°: linear_likelihood(a, b)")
print("  - è®¡ç®—æ¨¡å‹é¢„æµ‹å€¼")
print("  - è®¡ç®—å¡æ–¹ç»Ÿè®¡é‡")
print("  - è¿”å›å¯¹æ•°ä¼¼ç„¶")

# ç¬¬å››æ­¥ï¼šé…ç½®MCMCå‚æ•°
print("\nğŸ“ æ­¥éª¤4: é…ç½®MCMCå‚æ•°")
print("-"*50)

# åŸºç¡€é…ç½®
basic_config = {
    'parameters': {
        'a': (2.0, 0.0, 5.0),     # (åˆå€¼, ä¸‹é™, ä¸Šé™)
        'b': (1.0, -2.0, 4.0)     # (åˆå€¼, ä¸‹é™, ä¸Šé™)
    },
    'mcmc': {
        'num_samples': 2000,      # æ€»æ ·æœ¬æ•°ï¼ˆä¼šè‡ªåŠ¨åˆ†é…åˆ°å„é“¾ï¼‰
        'num_warmup': 500,        # é¢„çƒ­æ­¥æ•°
        'num_chains': 4           # é“¾æ•°ï¼ˆå¹¶è¡Œé‡‡æ ·ï¼‰
    }
}

print("é…ç½®è¯´æ˜:")
print("  parameters: å®šä¹‰å¾…ä¼°è®¡çš„å‚æ•°")
print("    æ ¼å¼: 'å‚æ•°å': (åˆå€¼, ä¸‹é™, ä¸Šé™)")
print("  mcmc:")
print("    num_samples: æ€»æ ·æœ¬æ•°ï¼ˆè‡ªåŠ¨åˆ†é…åˆ°å„é“¾ï¼‰")
print("    num_warmup: é¢„çƒ­æ­¥æ•°ï¼ˆä¸¢å¼ƒï¼‰")  
print("    num_chains: é“¾æ•°ï¼ˆå»ºè®®â‰¤CPUæ ¸æ•°ï¼‰")

# ç¬¬äº”æ­¥ï¼šè¿è¡ŒMCMC
print("\nğŸ“ æ­¥éª¤5: è¿è¡ŒMCMCé‡‡æ ·")
print("-"*50)

from hicosmo.samplers import MCMC

print("åˆ›å»ºMCMCå¯¹è±¡å¹¶è¿è¡Œ:")
mcmc = MCMC(
    config=basic_config,
    likelihood_func=linear_likelihood,
    optimize_init=True,           # æ˜¯å¦ä¼˜åŒ–åˆå§‹å€¼
    chain_name="example_linear"   # é“¾åç§°ï¼ˆç”¨äºä¿å­˜ï¼‰
)

# è¿è¡Œé‡‡æ ·
samples = mcmc.run()

print(f"\nâœ… é‡‡æ ·å®Œæˆï¼è·å¾— {len(samples['a'])} ä¸ªæ ·æœ¬")

# ç¬¬å…­æ­¥ï¼šåˆ†æç»“æœ
print("\nğŸ“ æ­¥éª¤6: åˆ†æé‡‡æ ·ç»“æœ")
print("-"*50)

print("ğŸ“Š å‚æ•°ä¼°è®¡ç»“æœ:")
for param in ['a', 'b']:
    values = samples[param]
    mean_val = np.mean(values)
    std_val = np.std(values)
    true_val = true_a if param == 'a' else true_b
    
    print(f"  {param}: {mean_val:.3f} Â± {std_val:.3f}")
    print(f"      çœŸå€¼: {true_val:.3f}")
    print(f"      åå·®: {abs(mean_val - true_val):.3f}")

# ç¬¬ä¸ƒæ­¥ï¼šæ”¶æ•›è¯Šæ–­
print("\nğŸ“ æ­¥éª¤7: æ”¶æ•›è¯Šæ–­")
print("-"*50)

try:
    # è·å–æ”¶æ•›è¯Šæ–­
    diagnostics = mcmc.get_diagnostics()
    
    print("æ”¶æ•›è¯Šæ–­æŒ‡æ ‡:")
    for param, diag in diagnostics.items():
        if isinstance(diag, dict):
            r_hat = diag.get('r_hat', 'N/A')
            ess = diag.get('ess', 'N/A')
            
            # åˆ¤æ–­æ”¶æ•›çŠ¶æ€
            converged = r_hat < 1.01 if r_hat != 'N/A' else False
            status = "âœ…æ”¶æ•›" if converged else "âŒæœªæ”¶æ•›"
            
            print(f"  {param}: RÌ‚ = {r_hat:.4f}, ESS = {ess:.0f} {status}")
            
except Exception as e:
    print(f"è¯Šæ–­å¤±è´¥: {e}")

# ç¬¬å…«æ­¥ï¼šé«˜çº§é…ç½®ç¤ºä¾‹
print("\nğŸ“ æ­¥éª¤8: é«˜çº§é…ç½®ç¤ºä¾‹")
print("-"*50)

advanced_config = {
    'parameters': {
        'a': (2.0, 0.0, 5.0),
        'b': (1.0, -2.0, 4.0)
    },
    'mcmc': {
        'num_samples': 4000,      # æ›´å¤šæ ·æœ¬
        'num_warmup': 1000,       # æ›´é•¿é¢„çƒ­
        'num_chains': 4,
        # é«˜çº§é€‰é¡¹
        'step_size': 0.1,         # æ­¥é•¿
        'target_accept_prob': 0.8, # ç›®æ ‡æ¥å—ç‡
        'max_tree_depth': 10      # æœ€å¤§æ ‘æ·±åº¦
    },
    'optimization': {
        'method': 'L-BFGS-B',     # ä¼˜åŒ–ç®—æ³•
        'maxiter': 1000           # æœ€å¤§è¿­ä»£æ•°
    }
}

print("é«˜çº§é…ç½®é€‰é¡¹:")
print("  step_size: NUTSç®—æ³•æ­¥é•¿")
print("  target_accept_prob: ç›®æ ‡æ¥å—æ¦‚ç‡")
print("  max_tree_depth: NUTSæœ€å¤§æ ‘æ·±åº¦")
print("  optimization: åˆå€¼ä¼˜åŒ–é…ç½®")

# ç¬¬ä¹æ­¥ï¼šå¤šç§ä½¿ç”¨æ¨¡å¼
print("\nğŸ“ æ­¥éª¤9: å¤šç§ä½¿ç”¨æ¨¡å¼")
print("-"*50)

print("ğŸ”¹ æ¨¡å¼1: åŸºç¡€MCMCï¼ˆä¸ä¼˜åŒ–åˆå€¼ï¼‰")
simple_config = basic_config.copy()
simple_mcmc = MCMC(simple_config, linear_likelihood, 
                  optimize_init=False, chain_name="simple_example")
simple_samples = simple_mcmc.run()
print(f"  åŸºç¡€é‡‡æ ·è·å¾— {len(simple_samples['a'])} ä¸ªæ ·æœ¬")

print("\nğŸ”¹ æ¨¡å¼2: æ£€æŸ¥ç‚¹ç»­è·‘")
# åˆ›å»ºæ–°çš„MCMCå¯¹è±¡ç”¨äºç»­è·‘
mcmc_resume = MCMC(basic_config, linear_likelihood, chain_name="resume_example")
print("  æ”¯æŒä»æ£€æŸ¥ç‚¹ç»­è·‘é‡‡æ ·")

print("\nğŸ”¹ æ¨¡å¼3: è‡ªå®šä¹‰æ•°æ®ä¼ é€’")
def likelihood_with_data(a, b, x_data, y_data, sigma):
    """å¸¦æ•°æ®å‚æ•°çš„ä¼¼ç„¶å‡½æ•°"""
    y_pred = a * x_data + b  
    chi2 = np.sum((y_data - y_pred)**2 / sigma**2)
    return -0.5 * chi2

# é…ç½®æ•°æ®ä¼ é€’
config_with_data = basic_config.copy()
config_with_data['data'] = {
    'x_data': x,
    'y_data': y_obs,  
    'sigma': y_err
}

mcmc_data = MCMC(config_with_data, likelihood_with_data, chain_name="with_data")
print("  æ”¯æŒé€šè¿‡configä¼ é€’æ•°æ®åˆ°ä¼¼ç„¶å‡½æ•°")

# ç¬¬åæ­¥ï¼šçŠ¶æ€æŸ¥è¯¢å’Œå·¥å…·
print("\nğŸ“ æ­¥éª¤10: å®ç”¨å·¥å…·å’ŒçŠ¶æ€æŸ¥è¯¢")
print("-"*50)

print("ğŸ”¹ å¤šæ ¸çŠ¶æ€æŸ¥è¯¢:")
status = Config.status()
print(f"  åˆå§‹åŒ–çŠ¶æ€: {status['initialized']}")
print(f"  CPUæ ¸å¿ƒæ•°: {status['config'].get('actual_cores', 'N/A')}")
print(f"  JAXè®¾å¤‡æ•°: {status['jax_devices']}")

print("\nğŸ”¹ MCMCçŠ¶æ€ä¿¡æ¯:")
print(f"  é‡‡æ ·å™¨ç±»å‹: {mcmc.sampler.__class__.__name__}")
print(f"  é“¾æ–¹æ³•: {mcmc.sampler.chain_method}")
print(f"  å‚æ•°æ•°é‡: {len(samples)}")

# ç¬¬åä¸€æ­¥ï¼šæœ€ä½³å®è·µå»ºè®®
print("\nğŸ“ æ­¥éª¤11: æœ€ä½³å®è·µå»ºè®®")
print("-"*50)

recommendations = [
    "ğŸ¯ é‡‡æ ·æ•°é‡: æ¯ä¸ªå‚æ•°è‡³å°‘1000ä¸ªæœ‰æ•ˆæ ·æœ¬",
    "â° é¢„çƒ­æ­¥æ•°: é€šå¸¸ä¸ºé‡‡æ ·æ•°çš„1/4åˆ°1/2",
    "ğŸ”— é“¾æ•°è®¾ç½®: å»ºè®®2-4æ¡é“¾ï¼Œä¸è¶…è¿‡CPUæ ¸æ•°",
    "ğŸ“Š æ”¶æ•›æ£€æŸ¥: ç¡®ä¿RÌ‚ < 1.01, ESS > 400",
    "ğŸ² åˆå€¼è®¾ç½®: å¯å¼€å¯optimize_initè‡ªåŠ¨ä¼˜åŒ–",
    "ğŸ’¾ é•¿æ—¶é—´è¿è¡Œ: ä½¿ç”¨æ£€æŸ¥ç‚¹åŠŸèƒ½é˜²æ­¢æ•°æ®ä¸¢å¤±",
    "ğŸ” ä¼¼ç„¶å‡½æ•°: é¿å…è¿”å›-infï¼Œä½¿ç”¨æ•°å€¼ç¨³å®šçš„è®¡ç®—"
]

print("æœ€ä½³å®è·µå»ºè®®:")
for rec in recommendations:
    print(f"  {rec}")

# ç¬¬åäºŒæ­¥ï¼šå®é™…éªŒè¯æµ‹è¯•
print("\nğŸ“ æ­¥éª¤12: å®Œæ•´åŠŸèƒ½éªŒè¯")
print("-"*50)

def run_comprehensive_test():
    """è¿è¡Œç»¼åˆæµ‹è¯•éªŒè¯æ‰€æœ‰åŠŸèƒ½"""
    
    print("ğŸ§ª è¿è¡Œç»¼åˆåŠŸèƒ½æµ‹è¯•...")
    
    # æµ‹è¯•ä¸åŒé…ç½®
    test_configs = [
        ("å•é“¾æµ‹è¯•", {'num_samples': 500, 'num_chains': 1}),
        ("å¤šé“¾æµ‹è¯•", {'num_samples': 1000, 'num_chains': 4}),
        ("é«˜é‡‡æ ·æµ‹è¯•", {'num_samples': 2000, 'num_chains': 2})
    ]
    
    results = {}
    
    for test_name, mcmc_params in test_configs:
        print(f"\n  ğŸ”¸ {test_name}:")
        
        test_config = basic_config.copy()
        test_config['mcmc'].update(mcmc_params)
        
        try:
            test_mcmc = MCMC(test_config, linear_likelihood, 
                           chain_name=f"test_{test_name.replace(' ', '_')}")
            test_samples = test_mcmc.run()
            
            # éªŒè¯ç»“æœ
            n_samples = len(test_samples['a'])
            a_mean = np.mean(test_samples['a'])
            b_mean = np.mean(test_samples['b'])
            
            # æ£€æŸ¥å‚æ•°ä¼°è®¡ç²¾åº¦
            a_error = abs(a_mean - true_a)
            b_error = abs(b_mean - true_b)
            
            accuracy = "ä¼˜ç§€" if max(a_error, b_error) < 0.1 else "è‰¯å¥½"
            
            print(f"    æ ·æœ¬æ•°: {n_samples}")
            print(f"    å‚æ•°a: {a_mean:.3f} (è¯¯å·®: {a_error:.3f})")
            print(f"    å‚æ•°b: {b_mean:.3f} (è¯¯å·®: {b_error:.3f})")
            print(f"    ç²¾åº¦è¯„ä¼°: {accuracy}")
            
            results[test_name] = {
                'success': True,
                'samples': n_samples,
                'accuracy': accuracy,
                'errors': (a_error, b_error)
            }
            
        except Exception as e:
            print(f"    âŒ æµ‹è¯•å¤±è´¥: {e}")
            results[test_name] = {'success': False, 'error': str(e)}
    
    return results

# è¿è¡Œæµ‹è¯•
test_results = run_comprehensive_test()

# è¾“å‡ºæµ‹è¯•æ€»ç»“
print("\nğŸ‰ æµ‹è¯•æ€»ç»“:")
print("="*60)

successful_tests = sum(1 for r in test_results.values() if r.get('success', False))
total_tests = len(test_results)

print(f"æµ‹è¯•é€šè¿‡ç‡: {successful_tests}/{total_tests}")

for test_name, result in test_results.items():
    status = "âœ… æˆåŠŸ" if result.get('success', False) else "âŒ å¤±è´¥"
    print(f"  {test_name}: {status}")
    
    if result.get('success', False):
        accuracy = result.get('accuracy', 'N/A')
        samples = result.get('samples', 'N/A')
        print(f"    æ ·æœ¬æ•°: {samples}, ç²¾åº¦: {accuracy}")

if successful_tests == total_tests:
    print("\nğŸŠ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼HiCosmo MCMC è¿è¡Œæ­£å¸¸ï¼")
    print("\nğŸ“š ä½¿ç”¨æ€»ç»“:")
    print("1. Config.init() - ä¸€è¡Œä»£ç é…ç½®å¤šæ ¸")
    print("2. å®šä¹‰ä¼¼ç„¶å‡½æ•°å’Œå‚æ•°é…ç½®")  
    print("3. MCMC(config, likelihood_func) åˆ›å»ºé‡‡æ ·å™¨")
    print("4. samples = mcmc.run() è¿è¡Œé‡‡æ ·")
    print("5. åˆ†æç»“æœå’Œæ”¶æ•›è¯Šæ–­")
else:
    print(f"\nâš ï¸ {total_tests - successful_tests} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

print("\n" + "="*60)
print("ğŸ“– å®Œæ•´ä½¿ç”¨æŒ‡å—ç»“æŸ")
print("="*60)